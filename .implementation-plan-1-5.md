# Plano de Implementação - Story 1-5: Validar estrutura CSV e filtrar/flag rows inválidas

**Data:** 2026-02-21
**Status:** Em andamento

## Resumo da Story
Implementar validação de DataFrames com schema pandera, flagging de rows inválidas, logging para ingest_logs, e abortar ingest se ultrapassar threshold de 10% (configurável).

## Análise do Código Existente
- ✅ Schema canônico já definido em `docs/schema.json`
- ✅ Mapper canônico já existe em `src/etl/mapper.py` com validação pandera
- ✅ Estrutura de testes em `tests/` com fixtures
- ✅ Pandera já está em `pyproject.toml`

## Tarefas e Subtarefas (da Story)

### 1. Implementar módulo `validation`
- [ ] Criar `src/validation.py` com função `validate_dataframe(df, schema) -> (valid_df, invalid_df, summary)`
- [ ] Usar schema pandera existente de `docs/schema.json`
- [ ] Separar rows válidas e inválidas
- [ ] Gerar summary com `rows_valid`, `rows_invalid`, `invalid_percent`

### 2. Implementar logging de rows inválidas
- [ ] Criar estrutura de `ingest_logs` (JSON ou CSV inicial)
- [ ] Campos: ticker, source, raw_file, row_index, reason_code, reason_message, job_id, created_at
- [ ] Gerar reason_codes claros (MISSING_COL, BAD_DATE, NON_NUMERIC_PRICE, etc)

### 3. Persistir rows inválidas
- [ ] Salvar em `raw/<provider>/invalid-<ticker>-<ts>.csv`
- [ ] Criar checksum SHA256 para arquivo inválido
- [ ] Referenciar em ingest_logs

### 4. Configuração de threshold
- [ ] Adicionar env var `VALIDATION_INVALID_PERCENT_THRESHOLD` (default 0.10)
- [ ] Abortar ingest se invalid% >= threshold
- [ ] Adicionar CLI flag `--validation-tolerance` em `src/main.py`

### 5. Testes
- [ ] Teste: arquivo 100% válido
- [ ] Teste: arquivo com <10% inválido (passa)
- [ ] Teste: arquivo com >=10% inválido (aborta)
- [ ] Teste: arquivo vazio
- [ ] Teste: arquivo com colunas faltando

### 6. Documentação
- [ ] Atualizar `docs/playbooks/quickstart-ticker.md`
- [ ] Documentar em `docs/sprint-reports/1-5-implementacao.md`

## Progresso
- [x] Análise do código existente
- [ ] Implementação do módulo validation
- [ ] Implementação do logging
- [ ] Implementação de threshold
- [ ] Testes
- [ ] Documentação

## Decisões Técnicas
1. Usar pandera schema já existente em `src/etl/mapper.py`
2. Logging inicial em JSON (`metadata/ingest_logs.json`)
3. Aproveitar estrutura de checksums existente
4. Integrar com pipeline existente em `src/ingest/pipeline.py`

## Notas
- Modo YOLO: implementar tudo de forma contínua até conclusão
- Seguir padrões do projeto: line-length=88, ruff, pytest
- Commits incrementais após cada conjunto lógico
