---
title: "3-2 Notebooks parametriz√°veis e quickstart notebook"
story: 3-2-notebooks-parametrizaveis-e-quickstart-notebook
status: ready-for-dev
---

# Story 3.2: notebooks-parametrizaveis-e-quickstart-notebook

Status: ready-for-dev

## Story

As a data scientist and developer,
I want parameterizable Jupyter notebooks and a Quickstart notebook for the project,
so that newcomers and automation pipelines can reproduce analyses and examples reliably.

## Acceptance Criteria

1. A Quickstart notebook exists that runs end-to-end using project example data (dados/ticker_example.csv) and documents required environment setup.
2. Notebooks accept parameters (via papermill or nbparameterise) for tickers, date range, and output paths.
3. Notebooks run headlessly in CI using the provided parameters and exit with non-zero on failures.
4. Notebooks include cells/sections with: data loading, preprocessing, computation of returns, basic visualizations, and saving outputs (CSV/figures).
5. README section documents how to run notebooks locally and via CI, including required Python dependencies and Example commands.
6. Unit/integration checks exist as lightweight sanity checks (e.g., verify output CSV has `Return` column) and are runnable by CI.

## Tasks / Subtasks

- [ ] Create `notebooks/quickstart.ipynb` demonstrating end-to-end flow with example ticker.
  - [ ] Ensure notebook runs with parameters for `ticker`, `start_date`, `end_date`, `output_dir`.
  - [ ] Add explanatory markdown cells and minimal visualizations.
- [ ] Add parameterization support using `papermill` (or alternative) and add example execution commands.
- [ ] Add CI job or script to execute notebook non-interactively and validate outputs.
- [ ] Add README docs with run examples and dependency list.
- [ ] Add lightweight sanity checks (script/tests) that validate notebook outputs.

## Dev Notes

- Prefer `papermill` for parameter injection (well-supported in CI). If avoiding new deps, implement simple parameter cell parsed by a runner script.
- Use existing data loader in `src/dados_b3.py` to load OHLCV/Adj Close and compute returns (`src.retorno` functions).
- Keep notebooks lightweight: rely on small sample dataset `dados/ticker_example.csv` for Quickstart to keep CI quick.
- Avoid heavy plotting libraries for CI; use matplotlib/seaborn with rasterized outputs or save simple CSVs for assertions.

### Project Structure Notes

- Place notebooks under `notebooks/` at repo root.
- CI runner/script: `scripts/run_notebooks.py` or GitHub Actions job that installs dev deps and runs `papermill`.
- Output artifacts: `artifacts/notebooks/<story-key>/` per run; Quickstart should write to a local tmp folder during CI.

### References

- Source: docs/implementation-artifacts (project conventions)
- Source: src/dados_b3.py, src/retorno.py for data loading and return calculations

## Dev Agent Record

### Agent Model Used

GPT-5 mini

### Debug Log References

- Generated by create-story workflow (YOLO mode). No external web research performed.

### Completion Notes List

- Story file created and marked `ready-for-dev`.

### File List

- notebooks/quickstart.ipynb (planned)

---

Completion: Ultimate context engine analysis (YOLO) produced an actionable story file for devs.

Issue: https://github.com/phbrgnomo/Analise-financeira-B3/issues/
